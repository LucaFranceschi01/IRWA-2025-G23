{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c9ad5d",
   "metadata": {},
   "source": [
    "# Part 3: Ranking and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428b58f",
   "metadata": {},
   "source": [
    "In this part of the project, you will experiment with different ranking algorithms that can be\n",
    "applied in a search engine. Your task is to design and implement a retrieval pipeline that:\n",
    "- Takes a query as input (a piece of text).\n",
    "- Finds all documents that contain all query terms (conjunctive query, i.e., AND semantics).\n",
    "- Sorts the matching documents by relevance using different ranking methods. The main goal of this assignment is to explore and compare various relevance scoring approaches. By the end, you should be able to analyze how different algorithms affect the ranking order of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84475c4",
   "metadata": {},
   "source": [
    "The main goal of this assignment is to explore and compare various relevance scoring approaches. By the end, you should be able to analyze how different algorithms affect the ranking order of documents.\n",
    "\n",
    "**Important: For this assignment, we only consider conjunctive queries (AND). This means that a document is included in the results only if it contains every word from the query.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f385a",
   "metadata": {},
   "source": [
    "## Prelude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dda5dc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6473ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, collections, string, re, math\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "from unidecode import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b0f7f",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c18368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADING\n",
    "DATA_PATH =  os.path.join(os.getcwd(), '../../data/')\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATA_PATH, 'fashion_products_cleaned.csv'))\n",
    "USED_TEXT_COLUMNS = ['title', 'description', 'brand', 'category', 'sub_category', 'seller']\n",
    "# USED_TEXT_COLUMNS = ['title', 'description']\n",
    "# USED_TEXT_COLUMNS = ['title']\n",
    "\n",
    "data[USED_TEXT_COLUMNS] = data[USED_TEXT_COLUMNS].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5f7fd",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad34a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function used in parts 1 and 2\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # Lowercase\n",
    "    text = text.translate(translator) # Remove punctuation\n",
    "    text = unidecode(text) # normalize\n",
    "    tokens = word_tokenize(text) # Tokenization\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words] # Remove stopwords and non-alphabetic tokens\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens] # Stemming \n",
    "    stemmed_tokens = [word for word in stemmed_tokens if len(word) > 2] # Remove short tokens\n",
    "    return stemmed_tokens\n",
    "\n",
    "def print_top_k_results(ranked_documents, k=20, columns=USED_TEXT_COLUMNS):\n",
    "    # Print header\n",
    "    print(\"=\" * 42)\n",
    "    print(f\"{'Rank':<6} | {'Document ID':<20} | {'Score':>10}\")\n",
    "    print(\"=\" * 42)\n",
    "\n",
    "    # Print each document row\n",
    "    for i, (score, doc) in enumerate(ranked_documents[:k], 1):\n",
    "        print(f\"{i:<6} | {doc:<20} | {score:>10.3f}\")\n",
    "\n",
    "    print(\"=\" * 42)\n",
    "\n",
    "def get_top_k_results(data: pd.DataFrame,\n",
    "                      ranked_documents,\n",
    "                      k: int | str = 'all',\n",
    "                      text_columns: list[str] = USED_TEXT_COLUMNS,\n",
    "                      num_columns: list[str] = []):\n",
    "    '''\n",
    "    Parameters\n",
    "    -----\n",
    "        data: pandas dataframe loaded from the cleaned csv file\n",
    "        ranked_documents: return of search_tf_idf or other search method\n",
    "        k: int of first documents to be retrieved or default is all documents as a string\n",
    "        columns: columns used for text searching, should be defined globally\n",
    "    '''\n",
    "    ranked_documents_df = pd.DataFrame(ranked_documents, columns=['score', 'pid'])\n",
    "\n",
    "    # they should be already ordered but just make sure\n",
    "    ranked_documents_df = ranked_documents_df.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    if k == 'all':\n",
    "        return ranked_documents_df.merge(data[['pid'] + text_columns + num_columns], on='pid', how='left')\n",
    "    \n",
    "    return ranked_documents_df.merge(data[['pid'] + text_columns + num_columns], on='pid', how='left')[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29586d48",
   "metadata": {},
   "source": [
    "## 1. You’re asked to provide 3 different ways of ranking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975728bf",
   "metadata": {},
   "source": [
    "#### a. TF-IDF + cosine similarity\n",
    "\n",
    "Classical scoring, which we have also seen during the practical labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4029a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tfidf(data, columns=['title', 'description', 'category']):\n",
    "    '''\n",
    "    Implement the inverted index and compute tf, df and idf\n",
    "\n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "    num_documents -- total number of documents\n",
    "\n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of document these keys appears in (and the positions) as values.\n",
    "    tf - normalized term frequency for each term in each document\n",
    "    df - number of documents each term appear in\n",
    "    idf - inverse document frequency of each term\n",
    "    '''\n",
    "\n",
    "    index = defaultdict(list)\n",
    "    tf = defaultdict(list)  #term frequencies of terms in documents (documents in the same order as in the main index)\n",
    "    df = defaultdict(int)  #document frequencies of terms in the corpus\n",
    "    idf = defaultdict(float)\n",
    "    N = len(data.index)\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        \n",
    "        page_id = row['pid']\n",
    "        terms = preprocess_text(' '.join(row[columns].values))\n",
    "\n",
    "        ## ===============================================================\n",
    "        ## create the index for the **current page** and store it in current_page_index\n",
    "        ## current_page_index ==> { ‘term1’: [current_doc, [list of positions]], ...,‘term_n’: [current_doc, [list of positions]]}\n",
    "\n",
    "        ## Example: if the curr_doc has id 1 and its text is\n",
    "        ##'web retrieval information retrieval':\n",
    "\n",
    "        ## current_page_index ==> { ‘web’: [1, [0]], ‘retrieval’: [1, [1,4]], ‘information’: [1, [2]]}\n",
    "\n",
    "        ## the term ‘web’ appears in document 1 in positions 0,\n",
    "        ## the term ‘retrieval’ appears in document 1 in positions 1 and 4\n",
    "        ## ===============================================================\n",
    "\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms):  ## terms contains page_title + page_text\n",
    "            try:\n",
    "                # if the term is already in the dict append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position)\n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term] = [page_id, array('I', [position])]  #'I' indicates unsigned int (int in Python)\n",
    "\n",
    "        # normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies (formula 2 above)\n",
    "        # norm is the same for all terms of a document.\n",
    "        norm = 0\n",
    "        for term, posting in current_page_index.items():\n",
    "            # posting will contain the list of positions for current term in current document.\n",
    "            # posting ==> [current_doc, [list of positions]]\n",
    "            # you can use it to infer the frequency of current term.\n",
    "            norm += len(posting[1]) ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        #calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, posting in current_page_index.items():\n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(len(posting[1]) / norm, 4)) ## SEE formula (1) above\n",
    "            #increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] += 1 # increment DF for current term\n",
    "\n",
    "        #merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "    # Compute IDF following the formula (3) above. HINT: use np.log\n",
    "    # Note: It is computed later after we know the df.\n",
    "    for term in df:\n",
    "        idf[term] = np.round(np.log(float(N / df[term])), 4)\n",
    "\n",
    "    return index, tf, df, idf\n",
    "\n",
    "def rank_documents(terms, docs, index, tf, idf):\n",
    "    '''\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    tf -- term frequencies\n",
    "    idf -- inverted document frequencies\n",
    "\n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    '''\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms\n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query.\n",
    "    # Example: collections.Counter(['hello','hello','world']) --> Counter({'hello': 2, 'world': 1})\n",
    "    # HINT: use when computing tf for query_vector\n",
    "\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]= query_terms_count[term] / query_norm * idf[term] #query_vector[0] corresponds to the first term in the query\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "            # Example of [doc_index, (doc, postings)]\n",
    "            # 0 (26, array('I', [1, 4, 12, 15, 22, 28, 32, 43, 51, 68, 333, 337]))\n",
    "            # 1 (33, array('I', [26, 33, 57, 71, 87, 104, 109]))\n",
    "            # term is in doc 26 in positions 1,4, .....\n",
    "            # term is in doc 33 in positions 26,33, .....\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term 'term' in the doc 26\n",
    "            if doc in docs: #if the odcument is in the list of documents retrieved (matching the query)\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]  # TODO: check if multiply for idf\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "    # see np.dot\n",
    "\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    #print document titles instead if document id's\n",
    "    #result_docs=[ title_index[x] for x in result_docs ]\n",
    "    if len(doc_scores) == 0:\n",
    "        print('No results found, try again')\n",
    "        query = input()\n",
    "        docs = search_tf_idf(query, index, tf, idf)\n",
    "    #print ('\\n'.join(result_docs), '\\n')\n",
    "    return doc_scores\n",
    "\n",
    "def search_tf_idf(query, index, tf, idf):\n",
    "    '''\n",
    "    output is the list of documents that contain any of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    '''\n",
    "    query = preprocess_text(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        \n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain 'term'\n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "\n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(set(term_docs))\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, tf, idf)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae772fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index, tf_index, df_index, idf_index = create_index_tfidf(data, USED_TEXT_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69709342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE SEARCH before we decide real queries used in all methods\n",
    "print_top_k_results(search_tf_idf('zipper sweater', inverted_index, tf_index, idf_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(get_top_k_results(data, search_tf_idf('zipper sweater', inverted_index, tf_index, idf_index), k=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ea516",
   "metadata": {},
   "source": [
    "### b. BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(data.apply(lambda x: ' '.join(x[USED_TEXT_COLUMNS].values).split(' '), axis=1).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70133a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_BM25(bm25, data, query, k=10):\n",
    "   \n",
    "    #apply preprocessing to the query using get_tokens and tranform it from string to list of terms\n",
    "    query = preprocess_text(query) # apply preprocessing\n",
    "\n",
    "    # score docs using a specific function of bm25\n",
    "    scores = np.array(bm25.get_scores(query))\n",
    "\n",
    "    # get indices of top k scores\n",
    "    idx = np.argpartition(scores, -k)[-k:]\n",
    "\n",
    "    # sort top k scores and return their indices\n",
    "    # if all the scores are 0 return empty list\n",
    "    if np.sum(scores[idx]) == 0:\n",
    "        return []\n",
    "    \n",
    "    # sort in descending order\n",
    "    top_indices = idx[np.argsort(-scores[idx])]\n",
    "\n",
    "    # build pairs (score, doc_id)\n",
    "    result = [(scores[i], data.iloc[i]['pid'] if 'pid' in data.columns else i) for i in top_indices]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54679d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_k_results(search_BM25(bm25, data, 'zipper sweater', k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6629d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(get_top_k_results(data, search_BM25(bm25, data, 'zipper sweater', k=20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c469f",
   "metadata": {},
   "source": [
    "### c. Your Score\n",
    "\n",
    "Here, the task is to create a new score. (Be creative , think about what factors could make a document more relevant to a query and include them in your formula.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022031d",
   "metadata": {},
   "source": [
    "Explain how the ranking differs when using TF-IDF and BM25, and think about the pros and cons of using each of them. Regarding your own score, justify the choice of the score (pros and cons). HINT: Look into numerical fields that each record has to build your score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2716391",
   "metadata": {},
   "source": [
    "**Custom Score Explanation**\n",
    "\n",
    "The idea is to combine in our score textual relevance (like we do in TF-IDF and BM25) together with numerical relevance (higher product average rating can be more relevant for the user searching for that product, or relevance for the user could be inversely proportional to the price, or higher discount could be relevant, etc). \n",
    "\n",
    "We will make a function where the user could decide which numerical column is more relevant, and another which combines all of them. \n",
    "\n",
    "The options for relevance order would be: \n",
    "- highest average_rating first\n",
    "- highest price first\n",
    "- lowest price first\n",
    "- highest discount first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfeef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_custom_score(df, query, columns=USED_TEXT_COLUMNS, method='tfidf'):\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # compute text scores\n",
    "    if method == 'tfidf':\n",
    "        index, tf, _, idf = create_index_tfidf(data, columns)        \n",
    "        ranked_docs = search_tf_idf(query, index, tf, idf)\n",
    "\n",
    "    elif method == 'bm25':\n",
    "        bm25 = BM25Okapi(df.apply(lambda x: ' '.join(x[columns].values).split(' '), axis=1).to_list())\n",
    "        ranked_docs = search_BM25(bm25, df, query, k=len(df))\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'tfidf' or 'bm25'\")\n",
    "\n",
    "    if not ranked_docs:\n",
    "        return []\n",
    "    \n",
    "    doc_ids = [pid for score, pid in ranked_docs]\n",
    "    text_scores = [score for score, pid in ranked_docs]\n",
    "    max_text_score = max(text_scores) if len(text_scores) > 0 else 1\n",
    "\n",
    "    for i, pid in enumerate(doc_ids): \n",
    "        row = df[df['pid'] == pid ].iloc[0]\n",
    "\n",
    "        # normalize text score\n",
    "        text_score = text_scores[i] / max_text_score\n",
    "\n",
    "        # numerical features\n",
    "        rating_score = row['average_rating'] / 5 if not pd.isna(row['average_rating']) else 0\n",
    "        discount_score = row['discount'] / 100 if not pd.isna(row['discount']) else 0\n",
    "        availability_score = 1 if row['out_of_stock'] == 0 else 0\n",
    "        price_score = 1 - (1 + np.log1p(row['selling_price'])) if not pd.isna(row['selling_price']) else 0\n",
    "\n",
    "        # combine with weights\n",
    "        combined_score = (0.4 * text_score +\n",
    "                          0.3 * rating_score +\n",
    "                          0.2 * discount_score +\n",
    "                          0.05 * availability_score +\n",
    "                          0.05 * price_score)\n",
    "        \n",
    "        results.append((combined_score, pid))\n",
    "\n",
    "    results.sort(reverse=True)\n",
    "    return results\n",
    "\n",
    "def rank_by_num(df, criterion='average_rating', ascending=False):\n",
    "\n",
    "    ranked_docs = search_tf_idf(\"zipper sweater\", inverted_index, tf_index, idf_index)\n",
    "\n",
    "    # filter df to only the documents retrieved\n",
    "    pids = [pid for _, pid in ranked_docs]\n",
    "    df_filtered = df[df['pid'].isin(pids)].copy()\n",
    "    \n",
    "    # sort by chosen criterion\n",
    "    df_filtered.sort_values(by=criterion, ascending=ascending, inplace=True)\n",
    "    \n",
    "    # return list of (score, pid), using text_score\n",
    "    score_mapping = {pid: score for score, pid in ranked_docs}\n",
    "    results = [(score_mapping[row['pid']], row['pid']) for _, row in df_filtered.iterrows()]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def custom_rank_sorted(df: pd.DataFrame,\n",
    "                       query: str = '',\n",
    "                       columns=USED_TEXT_COLUMNS,\n",
    "                       method='tfidf',\n",
    "                       ranked_docs=None,\n",
    "                       criterion: list[str] = ['average_rating'],\n",
    "                       ascending: list[bool] = [False]):\n",
    "    '''\n",
    "    Computes custom score (or passed as parameter) and returns a sorted result based on criterion and ascending.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    df : pd.DataFrame (data)\n",
    "\n",
    "    (query, columns, method) : are only used if ranked_docs == None\n",
    "        used to calculate the combined score\n",
    "\n",
    "    ranked_docs : in case the combined score is already calculated\n",
    "\n",
    "    criterion : column name used to order in result from search\n",
    "\n",
    "    ascending : bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[(score, doc_id)]\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    custom_rank_sorted(data, query='zipper sweater', criterion='average_rating', ascending=False)\n",
    "    custom_rank_sorted(data, ranked_docs=tf_idf_ranked_docs, criterion='average_rating', ascending=False)\n",
    "    '''\n",
    "    \n",
    "    if ranked_docs == None:\n",
    "        ranked_docs = compute_custom_score(df, query, columns, method)\n",
    "    \n",
    "    # filter df to only the documents retrieved\n",
    "    pids = [pid for _, pid in ranked_docs]\n",
    "    df_filtered = df[df['pid'].isin(pids)].copy()\n",
    "    \n",
    "    # sort by chosen criterion\n",
    "    df_filtered.sort_values(by=criterion, ascending=ascending, inplace=True)\n",
    "    \n",
    "    # return list of (score, pid), using text_score\n",
    "    score_mapping = {pid: score for score, pid in ranked_docs}\n",
    "    results = [(score_mapping[row['pid']], row['pid']) for _, row in df_filtered.iterrows()]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scores = compute_custom_score(data, 'zipper sweater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank by highest rating\n",
    "criterion_columns=['average_rating']\n",
    "ascending_columns=[False]\n",
    "\n",
    "# numeric_ranking = custom_rank_sorted(data, query='zipper sweater', criterion='average_rating', ascending=False)\n",
    "numeric_ranking = custom_rank_sorted(data, ranked_docs=custom_scores, criterion=criterion_columns, ascending=ascending_columns)\n",
    "display(get_top_k_results(data, numeric_ranking, k=20, num_columns=criterion_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank by lowest price\n",
    "criterion_columns=['selling_price']\n",
    "ascending_columns=[True]\n",
    "\n",
    "numeric_ranking = custom_rank_sorted(data, ranked_docs=custom_scores, criterion=criterion_columns, ascending=ascending_columns)\n",
    "display(get_top_k_results(data, numeric_ranking, k=20, num_columns=criterion_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75fd919",
   "metadata": {},
   "source": [
    "## 2. Implement **word2vec + cosine ranking** score.\n",
    "\n",
    "Return a top-20 list of documents for each of the 5 queries defined in the Part 2 of your project, using search and word2vec + cosine similarity ranking.\n",
    "​\n",
    "\n",
    "To represent a piece of **text** using **word2vec**, we create a **single vector** that represents the entire text. This vector has the same number of dimensions as the word vectors and is calculated by **averaging the vectors of all words** in the text.\n",
    "\n",
    "**Example:​**\n",
    "\n",
    "Consider the text:\n",
    "```\n",
    "“Wireless Bluetooth headphones with noise cancellation”\n",
    "```\n",
    "\n",
    "Suppose we have Word2Vec vectors for each word:\n",
    "\n",
    "* Wireless → v1\n",
    "* Bluetooth → v2\n",
    "* headphones → v3\n",
    "* with → v4\n",
    "* noise → v5\n",
    "* cancellation → v6\n",
    "\n",
    "All vectors have the same number of dimensions. To represent the text as a single vector, we average the word vectors:\n",
    "\n",
    "```\n",
    "Text vector = (v1 + v2 + v3 + v4 + v5 + v6) ÷ 6\n",
    "```\n",
    "\n",
    "The resulting vector has the same number of dimensions as the individual word vectors and represents the content of the entire text. This approach allows us to compare texts based on their vector representations for tasks like search or recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a353088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bd370",
   "metadata": {},
   "source": [
    "## 3. Can you imagine a better representation than word2vec?\n",
    "\n",
    "Justify your answer. (**HINT** - what about Doc2vec? Sentence2vec? What are the pros and cons?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387d79a",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
