{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c9ad5d",
   "metadata": {},
   "source": [
    "# Part 3: Ranking and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428b58f",
   "metadata": {},
   "source": [
    "In this part of the project, you will experiment with different ranking algorithms that can be\n",
    "applied in a search engine. Your task is to design and implement a retrieval pipeline that:\n",
    "- Takes a query as input (a piece of text).\n",
    "- Finds all documents that contain all query terms (conjunctive query, i.e., AND semantics).\n",
    "- Sorts the matching documents by relevance using different ranking methods. The main goal of this assignment is to explore and compare various relevance scoring approaches. By the end, you should be able to analyze how different algorithms affect the ranking order of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84475c4",
   "metadata": {},
   "source": [
    "The main goal of this assignment is to explore and compare various relevance scoring approaches. By the end, you should be able to analyze how different algorithms affect the ranking order of documents.\n",
    "\n",
    "**Important: For this assignment, we only consider conjunctive queries (AND). This means that a document is included in the results only if it contains every word from the query.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6473ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c18368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29586d48",
   "metadata": {},
   "source": [
    "## 1. You’re asked to provide 3 different ways of ranking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975728bf",
   "metadata": {},
   "source": [
    "#### a. TF-IDF + cosine similarity\n",
    "\n",
    "Classical scoring, which we have also seen during the practical labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4029a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ea516",
   "metadata": {},
   "source": [
    "### b. BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c469f",
   "metadata": {},
   "source": [
    "### c. Your Score\n",
    "\n",
    "Here, the task is to create a new score. (Be creative , think about what factors could make a document more relevant to a query and include them in your formula.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfeef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022031d",
   "metadata": {},
   "source": [
    "Explain how the ranking differs when using TF-IDF and BM25, and think about the pros and cons of using each of them. Regarding your own score, justify the choice of the score (pros and cons). HINT: Look into numerical fields that each record has to build your score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2716391",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75fd919",
   "metadata": {},
   "source": [
    "## 2. Implement **word2vec + cosine ranking** score.\n",
    "\n",
    "Return a top-20 list of documents for each of the 5 queries defined in the Part 2 of your project, using search and word2vec + cosine similarity ranking.\n",
    "​\n",
    "\n",
    "To represent a piece of **text** using **word2vec**, we create a **single vector** that represents the entire text. This vector has the same number of dimensions as the word vectors and is calculated by **averaging the vectors of all words** in the text.\n",
    "\n",
    "**Example:​**\n",
    "\n",
    "Consider the text:\n",
    "```\n",
    "“Wireless Bluetooth headphones with noise cancellation”\n",
    "```\n",
    "\n",
    "Suppose we have Word2Vec vectors for each word:\n",
    "\n",
    "* Wireless → v1\n",
    "* Bluetooth → v2\n",
    "* headphones → v3\n",
    "* with → v4\n",
    "* noise → v5\n",
    "* cancellation → v6\n",
    "\n",
    "All vectors have the same number of dimensions. To represent the text as a single vector, we average the word vectors:\n",
    "\n",
    "```\n",
    "Text vector = (v1 + v2 + v3 + v4 + v5 + v6) ÷ 6\n",
    "```\n",
    "\n",
    "The resulting vector has the same number of dimensions as the individual word vectors and represents the content of the entire text. This approach allows us to compare texts based on their vector representations for tasks like search or recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a353088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bd370",
   "metadata": {},
   "source": [
    "## 3. Can you imagine a better representation than word2vec?\n",
    "\n",
    "Justify your answer. (**HINT** - what about Doc2vec? Sentence2vec? What are the pros and cons?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387d79a",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
