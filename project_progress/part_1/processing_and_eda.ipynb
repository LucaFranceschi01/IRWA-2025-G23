{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84fe4d8d",
   "metadata": {},
   "source": [
    "# Part 1: Text Processing and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b198f",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb905e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, string\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a419a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =  os.path.join(os.getcwd(), '../../data/')\n",
    "doc_path = os.path.join(data_path, 'fashion_products_dataset.json')\n",
    "\n",
    "df = pd.read_json(doc_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf2534",
   "metadata": {},
   "source": [
    "1. As a first step, you must pre-process the documents. In particular, for the text fields (title,\n",
    "description) you should:\n",
    "\n",
    "- Removing stop words\n",
    "- Tokenization\n",
    "- Removing punctuation marks\n",
    "- Stemming\n",
    "- and... anything else you think it's needed (bonus point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9628e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def preprocess_string(s):\n",
    "    s = str.lower(s)\n",
    "    s.translate(translator) # remove punctuation marks\n",
    "    s = unidecode(s) # normalize\n",
    "    s = s.split() # tokenize\n",
    "    s = [word for word in s if word not in stop_words] # removing stop words\n",
    "    s = [stemmer.stem(word) for word in s] # stemming\n",
    "    return s\n",
    "\n",
    "\n",
    "df['description'] = df['description'].apply(preprocess_string) # TODO: add things\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2e779",
   "metadata": {},
   "source": [
    "2. Take into account that for future queries, the final output must return (when present) the following information for each of the  elected documents: pid, title, description, brand, category, sub_category, product_details, seller, out_of_stock, selling_price, discount, actual_price, average_rating, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b69fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecee2ad",
   "metadata": {},
   "source": [
    "3. Decide how to handle the fields category, sub_category, brand, product_details, and seller during pre-processing. Should they be merged into a single text field, indexed as separate fields in the inverted index or any other alternative? Justify your choice, considering how their distinctiveness may affect retrieval effectiveness. What are pros and cons of each approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f819bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd9f47",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5c438",
   "metadata": {},
   "source": [
    "4. Consider the fields out_of_stock, selling_price, discount, actual_price, and average_rating. Decide how these should be handled during pre-processing to use in further search. Should they be indexed as textual terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b065bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcaaef",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642171d5",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1924d",
   "metadata": {},
   "source": [
    "When working with data, it is important to have a better understanding of the content and some statistics. Provide an exploratory data analysis to describe the dataset you are working on in this project and explain the decisions made for the analysis. For example, word counting distribution, average sentence length, vocabulary size, ranking of products based on rating, price, discount, top sellers and brands, out_of_stock distribution, word clouds for the most frequent words, and entity recognition. Feel free to do the exploratory analysis and report your findings in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
